---
title: "Wrapped Gaussian on the manifold of Symmetric Positive Definite Matrices"
collection: preprints
layout: single
permalink: /preprint/2025-02-arxiv_WG
#excerpt: 'This paper is about the number 1. The number 2 is left for future work.'
date: 2025-02-03
#venue: 'Transactions on Machine Learning Research'
authors: 'TdS, Sylvain Chevallier and Fabien Lotte, Florian Yger,'
paperurl: 'http://thibaultdesurrel.github.io/files/Arxiv_WG.pdf'
#HAL: 'https://hal.science/hal-04942016'
arXiv: 'https://arxiv.org/abs/2502.01512'
#citation: 'Your Name, You. (2009). &quot;Paper Title Number 1.&quot; <i>Journal 1</i>. 1(1).'
---


Circular and non-flat data distributions are prevalent across diverse domains of data science, yet their specific geometric structures often remain underutilized in machine learning frameworks. A principled approach to accounting for the underlying geometry of such data is pivotal, particularly when extending statistical models, like the pervasive Gaussian distribution. In this work, we tackle those issue by focusing on the manifold of symmetric positive definite matrices, a key focus in information geometry. We introduced a non-isotropic wrapped Gaussian by leveraging the exponential map, we derive theoretical properties of this distribution and propose a maximum likelihood framework for parameter estimation. Furthermore, we reinterpret established classifiers on SPD through a probabilistic lens and introduce new classifiers based on the wrapped Gaussian model. Experiments on synthetic and real-world datasets demonstrate the robustness and flexibility of this geometry-aware distribution, underscoring its potential to advance manifold-based data analysis. This work lays the groundwork for extending classical machine learning and statistical methods to more complex and structured data.